{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGFbhfGWUCSa"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5UBRdvav8wwK"
   },
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.proxy import *\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "\n",
    "# processing\n",
    "#!pip install tldextract #-> install package\n",
    "import tldextract\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping \"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SELENIUM ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recaptcha(driver):\n",
    "    try:\n",
    "        WebDriverWait(driver, 20).until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR,\"iframe[title='reCAPTCHA']\")))\n",
    "        print('*** reCaptcha détécté ***')\n",
    "        print('*** 1min pour résoudre le puzzle avant suite du script ***\\n')\n",
    "        time.sleep(60)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapator(search_terms, nb_pages): # à ajouter -> proxy, langue, headless browser...\n",
    "    \n",
    "    \"\"\"\n",
    "    -----------------------------------------\n",
    "    fonction pour scrapper serp google (SEO only)\n",
    "    -----------------------------------------\n",
    "    search_terms -> liste de search terms à utiliser\n",
    "    nb_pages -> nombre de pages à scrapper (int)\n",
    "    visible -> si on veut visualiser le browser ou non - par défaut = True donc visible (bool)\n",
    "    (proxy -> proxy à utiliser (WIP))\n",
    "    \n",
    "    return -> df\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = datetime.now() # à formater\n",
    "    print(f'Début du programme : {start_time}\\n') # à formater\n",
    "    \n",
    "    # AJOUTER GESTION ERREUR QUELQUEPART\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # initier webdriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    #if visible is False:\n",
    "    #    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options = options)\n",
    "    \n",
    "    #action = ActionChains(driver) -> à enlever ? \n",
    "    \n",
    "    print('***** scrapping en cours *****')\n",
    "    \n",
    "    # boucle sur search terms\n",
    "    for term in search_terms:\n",
    "        \n",
    "        print(f'\\n**** search term - {term} ****\\n')\n",
    "        \n",
    "        # aller sur google\n",
    "        driver.get(\"https://google.com\")\n",
    "        try:\n",
    "            # accepter blablabla\n",
    "            WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button#L2AGLb.tHlp8d\"))).click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # petite pause\n",
    "        time.sleep(round(random.uniform(1, 10), 1))\n",
    "    \n",
    "        # trouver la search bar\n",
    "        elem = driver.find_element(By.NAME, \"q\")\n",
    "        elem.clear() # pour la vider si elle est pas vide\n",
    "    \n",
    "        # entrer element de recherche dans la search bar\n",
    "        elem.send_keys(term)\n",
    "        time.sleep(2) # à ne pas oublier sinon va juste aller à la ligne après le mot sans faire entrer\n",
    "        elem.send_keys(Keys.RETURN)\n",
    "    \n",
    "        # petite pause\n",
    "        time.sleep(round(random.uniform(1, 10), 1))\n",
    "    \n",
    "        textes = []\n",
    "        titres = []\n",
    "        url = []\n",
    "        image = []\n",
    "        page_pos = []\n",
    "        pages = []\n",
    "        seaseo = []\n",
    "        n = 0\n",
    "\n",
    "        # prendre les infos des nb_pages pages\n",
    "        while n < nb_pages:\n",
    "            \n",
    "            # compteur de page\n",
    "            n += 1\n",
    "            print(f'*** -- scrapping page {n} -- ***')\n",
    "            \n",
    "            # captcha\n",
    "            recaptcha(driver)\n",
    "\n",
    "            # trouver tous les articles d'une page\n",
    "            driver.save_screenshot('screenshot.png')\n",
    "            articles_SEO = driver.find_elements(By.CLASS_NAME, \"MjjYud\") # -> SEO\n",
    "            articles_SEA = driver.find_elements(By.CLASS_NAME, \"uEierd\") # -> SEA\n",
    "            position = 0\n",
    "    \n",
    "            # boucler sur articles SEO\n",
    "            for article in articles_SEO:\n",
    "                \n",
    "                try:\n",
    "                    # titre\n",
    "                    title = article.find_element(By.TAG_NAME, 'h3') # quand pas de titre pour le seo -> pas vrai article seo\n",
    "                    titres.append(title.text)\n",
    "                    \n",
    "                    # position\n",
    "                    position += 1\n",
    "                    page_pos.append(position)\n",
    "        \n",
    "                    # texte\n",
    "                    textes.append(article.text)\n",
    "                    \n",
    "                    # liens\n",
    "                    link = article.find_element(By.TAG_NAME, 'a')\n",
    "                    url.append(link.get_attribute(\"href\"))\n",
    "                    \n",
    "                    # page\n",
    "                    pages.append(n)\n",
    "                    \n",
    "                    # type de contenu\n",
    "                    seaseo.append('SEO')\n",
    "                    \n",
    "                    # Image\n",
    "                    try:\n",
    "                        img = article.find_element(By.CLASS_NAME, 'Z26q7c.UK95Uc.Sth6v')\n",
    "                        image.append('Oui')\n",
    "                    except:\n",
    "                        image.append('Non')\n",
    "                    \n",
    "                except:\n",
    "                    titres.append('vide')\n",
    "                    page_pos.append('vide')\n",
    "                    textes.append('vide')\n",
    "                    url.append('vide')\n",
    "                    pages.append('vide')\n",
    "                    image.append('vide')\n",
    "                    seaseo.append('SEO vide')\n",
    "    \n",
    "            position = 0    \n",
    "            # boucler sur articles SEA\n",
    "            for add in articles_SEA:\n",
    "                \n",
    "                # position\n",
    "                position += 1\n",
    "                page_pos.append(position)\n",
    "        \n",
    "                # texte\n",
    "                textes.append(add.text)\n",
    "        \n",
    "                # titre\n",
    "                try:\n",
    "                    title = add.find_element(By.CLASS_NAME, 'CCgQ5.vCa9Yd.QfkTvb.N8QANc.MUxGbd.v0nnCb')\n",
    "                    titres.append(title.text)\n",
    "                except:\n",
    "                    titres.append('erreur')\n",
    "\n",
    "                # liens\n",
    "                try:\n",
    "                    link = add.find_element(By.TAG_NAME, 'a')\n",
    "                    url.append(link.get_attribute(\"href\"))\n",
    "                except:\n",
    "                    url.append('erreur')\n",
    "                \n",
    "                # page\n",
    "                pages.append(n)\n",
    "                \n",
    "                # type de contenu\n",
    "                seaseo.append('SEA')\n",
    "                \n",
    "                try:\n",
    "                    img = add.find_element(By.CLASS_NAME, 'g-img.ZGomKf')\n",
    "                    image.append('Oui')\n",
    "                except:\n",
    "                    image.append('Non')\n",
    "\n",
    "            \n",
    "            # se déplacer en bas de la page\n",
    "            bottom_element = driver.find_element(By.ID, 'botstuff')\n",
    "            bottom_element.location_once_scrolled_into_view\n",
    "    \n",
    "            # changer de page\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, (\"//*[contains(text(),'Suivant')]\")).click()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "            # petite pause\n",
    "            time.sleep(round(random.uniform(1, 10), 1))\n",
    "        \n",
    "        # définir le bon indice à prendre quand pas le même nombre d'élements\n",
    "\n",
    "        if len(titres) <= len(url) and len(titres) <= len(textes):\n",
    "            size = len(titres)\n",
    "        elif len(textes) <= len(url) and len(textes) <= len(titres):\n",
    "            size = len(textes)\n",
    "        elif len(url) <= len(textes) and len(url) <= len(titres):\n",
    "            size = len(url)\n",
    "        elif len(url) == len(textes) and len(url) == len(titres) and len(textes) == len(titres):\n",
    "            print('même taille')\n",
    "            size = len(url)\n",
    "        else:\n",
    "            print('problème quelque part')\n",
    "            size = 0\n",
    "        \n",
    "        # mettre le tout dans un df\n",
    "        df_term = pd.DataFrame()\n",
    "        df_term['url'] = url[0:size]\n",
    "        df_term['titles'] = titres[0:size]\n",
    "        df_term['texte'] = textes[0:size]\n",
    "        df_term['search_term'] = term\n",
    "        df_term['pages'] = pages[0:size]\n",
    "        df_term['page_position'] = page_pos[0:size]\n",
    "        df_term['type'] = seaseo[0:size]\n",
    "        df_term['images'] = image[0:size]\n",
    "    \n",
    "        df_term.drop(df_term.loc[df_term['titles'] == ''].index, inplace = True)\n",
    "        df_term.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "        df_term['company'] = df_term['url'].apply(lambda x : tldextract.extract(x).domain)\n",
    "        df_term['domain'] = df_term['url'].apply(lambda x : urlparse(x).netloc)\n",
    "        #df_term['serp_position'] = np.arange(1, df_term.shape[0] + 1)\n",
    "        \n",
    "        # Merger avec les données des messages précédents\n",
    "        df = pd.concat([df, df_term], ignore_index = True)\n",
    "        df['Date'] = date.today().strftime(\"%d/%m/%y\")\n",
    "        \n",
    "        print(f'\\nFin du scrapping pour le search term : {term} ')\n",
    "    \n",
    "    # quitter driver\n",
    "    driver.close()\n",
    "    \n",
    "    end_time = datetime.now() # à formater\n",
    "    print('Duration: {}'.format(end_time - start_time)) # à formater\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du programme : 2023-11-01 12:58:19.530897\n",
      "\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriver' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/envs/artefact/lib/python3.9/site-packages/selenium/webdriver/common/service.py:71\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m     cmd\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_line_args())\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(cmd, env\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[1;32m     72\u001b[0m                                     close_fds\u001b[39m=\u001b[39;49msystem() \u001b[39m!=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mWindows\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     73\u001b[0m                                     stdout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_file,\n\u001b[1;32m     74\u001b[0m                                     stderr\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_file,\n\u001b[1;32m     75\u001b[0m                                     stdin\u001b[39m=\u001b[39;49mPIPE,\n\u001b[1;32m     76\u001b[0m                                     creationflags\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreationflags)\n\u001b[1;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    952\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    953\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    954\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    955\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    956\u001b[0m                         errread, errwrite,\n\u001b[1;32m    957\u001b[0m                         restore_signals,\n\u001b[1;32m    958\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    959\u001b[0m                         start_new_session)\n\u001b[1;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/subprocess.py:1821\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1820\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1821\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1822\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'chromedriver'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m/Users/lucilerabeau/code/LucileRb/article_text_analysis/serpscrapor_soil.ipynb Cell 7\u001b[0m line \u001b[0;36mscrapator\u001b[0;34m(search_terms, nb_pages)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucilerabeau/code/LucileRb/article_text_analysis/serpscrapor_soil.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m options \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39mChromeOptions()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucilerabeau/code/LucileRb/article_text_analysis/serpscrapor_soil.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m#if visible is False:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucilerabeau/code/LucileRb/article_text_analysis/serpscrapor_soil.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m#    options.add_argument(\"--headless\")\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lucilerabeau/code/LucileRb/article_text_analysis/serpscrapor_soil.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39;49mChrome(options \u001b[39m=\u001b[39;49m options)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucilerabeau/code/LucileRb/article_text_analysis/serpscrapor_soil.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#action = ActionChains(driver) -> à enlever ? \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucilerabeau/code/LucileRb/article_text_analysis/serpscrapor_soil.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m***** scrapping en cours *****\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/envs/artefact/lib/python3.9/site-packages/selenium/webdriver/chrome/webdriver.py:70\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m service:\n\u001b[1;32m     68\u001b[0m     service \u001b[39m=\u001b[39m Service(executable_path, port, service_args, service_log_path)\n\u001b[0;32m---> 70\u001b[0m \u001b[39msuper\u001b[39;49m(WebDriver, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(DesiredCapabilities\u001b[39m.\u001b[39;49mCHROME[\u001b[39m'\u001b[39;49m\u001b[39mbrowserName\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m\"\u001b[39;49m\u001b[39mgoog\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     71\u001b[0m                                 port, options,\n\u001b[1;32m     72\u001b[0m                                 service_args, desired_capabilities,\n\u001b[1;32m     73\u001b[0m                                 service_log_path, service, keep_alive)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/envs/artefact/lib/python3.9/site-packages/selenium/webdriver/chromium/webdriver.py:90\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mservice cannot be None\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice \u001b[39m=\u001b[39m service\n\u001b[0;32m---> 90\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mservice\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m     92\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     RemoteWebDriver\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m     94\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m     95\u001b[0m         command_executor\u001b[39m=\u001b[39mChromiumRemoteConnection(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m             keep_alive\u001b[39m=\u001b[39mkeep_alive, ignore_proxy\u001b[39m=\u001b[39m_ignore_proxy),\n\u001b[1;32m     99\u001b[0m         options\u001b[39m=\u001b[39moptions)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/envs/artefact/lib/python3.9/site-packages/selenium/webdriver/common/service.py:81\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m     80\u001b[0m     \u001b[39mif\u001b[39;00m err\u001b[39m.\u001b[39merrno \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mENOENT:\n\u001b[0;32m---> 81\u001b[0m         \u001b[39mraise\u001b[39;00m WebDriverException(\n\u001b[1;32m     82\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m executable needs to be in PATH. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[1;32m     83\u001b[0m                 os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_error_message)\n\u001b[1;32m     84\u001b[0m         )\n\u001b[1;32m     85\u001b[0m     \u001b[39melif\u001b[39;00m err\u001b[39m.\u001b[39merrno \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mEACCES:\n\u001b[1;32m     86\u001b[0m         \u001b[39mraise\u001b[39;00m WebDriverException(\n\u001b[1;32m     87\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m executable may have wrong permissions. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[1;32m     88\u001b[0m                 os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_error_message)\n\u001b[1;32m     89\u001b[0m         )\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: 'chromedriver' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# test scraping 5 pages\n",
    "mots = ['monitoring reporting verification soil', 'soil monitoring reporting']\n",
    "\n",
    "df = scrapator(mots, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>titles</th>\n",
       "      <th>texte</th>\n",
       "      <th>search_term</th>\n",
       "      <th>pages</th>\n",
       "      <th>page_position</th>\n",
       "      <th>type</th>\n",
       "      <th>images</th>\n",
       "      <th>company</th>\n",
       "      <th>domain</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://scholar.google.fr/scholar?q=monitoring...</td>\n",
       "      <td>Articles universitaires correspondant aux term...</td>\n",
       "      <td>Articles universitaires correspondant aux term...</td>\n",
       "      <td>monitoring reporting verification soil</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>google</td>\n",
       "      <td>scholar.google.fr</td>\n",
       "      <td>30/10/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.horizon-europe.gouv.fr/monitoring-...</td>\n",
       "      <td>Monitoring, reporting and verification of soil...</td>\n",
       "      <td>Monitoring, reporting and verification of soil...</td>\n",
       "      <td>monitoring reporting verification soil</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>horizon-europe</td>\n",
       "      <td>www.horizon-europe.gouv.fr</td>\n",
       "      <td>30/10/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.fao.org/documents/card/en?details=...</td>\n",
       "      <td>A protocol for measurement, monitoring, report...</td>\n",
       "      <td>A protocol for measurement, monitoring, report...</td>\n",
       "      <td>monitoring reporting verification soil</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>fao</td>\n",
       "      <td>www.fao.org</td>\n",
       "      <td>30/10/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://gi.copernicus.org/articles/11/93/2022/</td>\n",
       "      <td>Towards agricultural soil carbon monitoring, r...</td>\n",
       "      <td>Towards agricultural soil carbon monitoring, r...</td>\n",
       "      <td>monitoring reporting verification soil</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>copernicus</td>\n",
       "      <td>gi.copernicus.org</td>\n",
       "      <td>30/10/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://cordis.europa.eu/project/id/101112754</td>\n",
       "      <td>Monitoring, Reporting and Verification of Soil...</td>\n",
       "      <td>Monitoring, Reporting and Verification of Soil...</td>\n",
       "      <td>monitoring reporting verification soil</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>europa</td>\n",
       "      <td>cordis.europa.eu</td>\n",
       "      <td>30/10/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>https://www.databridgemarketresearch.com/repor...</td>\n",
       "      <td>Global Soil Monitoring Market – Industry Trend...</td>\n",
       "      <td>Global Soil Monitoring Market – Industry Trend...</td>\n",
       "      <td>soil monitoring reporting</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>databridgemarketresearch</td>\n",
       "      <td>www.databridgemarketresearch.com</td>\n",
       "      <td>30/10/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>https://www.marketsandmarkets.com/Market-Repor...</td>\n",
       "      <td>Soil Monitoring Market Size, Share, Trends, an...</td>\n",
       "      <td>Soil Monitoring Market Size, Share, Trends, an...</td>\n",
       "      <td>soil monitoring reporting</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>marketsandmarkets</td>\n",
       "      <td>www.marketsandmarkets.com</td>\n",
       "      <td>30/10/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>https://forest.moscowfsl.wsu.edu/smp/solo/GeoP...</td>\n",
       "      <td>Idaho Panhandle National Forest: Soil Monitori...</td>\n",
       "      <td>Idaho Panhandle National Forest: Soil Monitori...</td>\n",
       "      <td>soil monitoring reporting</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>wsu</td>\n",
       "      <td>forest.moscowfsl.wsu.edu</td>\n",
       "      <td>30/10/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>https://environment.govt.nz/publications/land-...</td>\n",
       "      <td>Land and soil monitoring: A guide for SoE and ...</td>\n",
       "      <td>Land and soil monitoring: A guide for SoE and ...</td>\n",
       "      <td>soil monitoring reporting</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>environment</td>\n",
       "      <td>environment.govt.nz</td>\n",
       "      <td>30/10/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>https://environmentclearance.nic.in/writereadd...</td>\n",
       "      <td>ANNEXURE VIII SOIL MONITORING REPORT</td>\n",
       "      <td>ANNEXURE VIII SOIL MONITORING REPORT\\nEnvironm...</td>\n",
       "      <td>soil monitoring reporting</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>environmentclearance</td>\n",
       "      <td>environmentclearance.nic.in</td>\n",
       "      <td>30/10/23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0    https://scholar.google.fr/scholar?q=monitoring...   \n",
       "1    https://www.horizon-europe.gouv.fr/monitoring-...   \n",
       "2    https://www.fao.org/documents/card/en?details=...   \n",
       "3       https://gi.copernicus.org/articles/11/93/2022/   \n",
       "4        https://cordis.europa.eu/project/id/101112754   \n",
       "..                                                 ...   \n",
       "200  https://www.databridgemarketresearch.com/repor...   \n",
       "201  https://www.marketsandmarkets.com/Market-Repor...   \n",
       "202  https://forest.moscowfsl.wsu.edu/smp/solo/GeoP...   \n",
       "203  https://environment.govt.nz/publications/land-...   \n",
       "204  https://environmentclearance.nic.in/writereadd...   \n",
       "\n",
       "                                                titles  \\\n",
       "0    Articles universitaires correspondant aux term...   \n",
       "1    Monitoring, reporting and verification of soil...   \n",
       "2    A protocol for measurement, monitoring, report...   \n",
       "3    Towards agricultural soil carbon monitoring, r...   \n",
       "4    Monitoring, Reporting and Verification of Soil...   \n",
       "..                                                 ...   \n",
       "200  Global Soil Monitoring Market – Industry Trend...   \n",
       "201  Soil Monitoring Market Size, Share, Trends, an...   \n",
       "202  Idaho Panhandle National Forest: Soil Monitori...   \n",
       "203  Land and soil monitoring: A guide for SoE and ...   \n",
       "204               ANNEXURE VIII SOIL MONITORING REPORT   \n",
       "\n",
       "                                                 texte  \\\n",
       "0    Articles universitaires correspondant aux term...   \n",
       "1    Monitoring, reporting and verification of soil...   \n",
       "2    A protocol for measurement, monitoring, report...   \n",
       "3    Towards agricultural soil carbon monitoring, r...   \n",
       "4    Monitoring, Reporting and Verification of Soil...   \n",
       "..                                                 ...   \n",
       "200  Global Soil Monitoring Market – Industry Trend...   \n",
       "201  Soil Monitoring Market Size, Share, Trends, an...   \n",
       "202  Idaho Panhandle National Forest: Soil Monitori...   \n",
       "203  Land and soil monitoring: A guide for SoE and ...   \n",
       "204  ANNEXURE VIII SOIL MONITORING REPORT\\nEnvironm...   \n",
       "\n",
       "                                search_term pages page_position type images  \\\n",
       "0    monitoring reporting verification soil     1             1  SEO    Non   \n",
       "1    monitoring reporting verification soil     1             2  SEO    Non   \n",
       "2    monitoring reporting verification soil     1             4  SEO    Non   \n",
       "3    monitoring reporting verification soil     1             5  SEO    Non   \n",
       "4    monitoring reporting verification soil     1             6  SEO    Non   \n",
       "..                                      ...   ...           ...  ...    ...   \n",
       "200               soil monitoring reporting     5            18  SEO    Non   \n",
       "201               soil monitoring reporting     5            19  SEO    Non   \n",
       "202               soil monitoring reporting     5            20  SEO    Non   \n",
       "203               soil monitoring reporting     5            21  SEO    Non   \n",
       "204               soil monitoring reporting     5            22  SEO    Non   \n",
       "\n",
       "                      company                            domain      Date  \n",
       "0                      google                 scholar.google.fr  30/10/23  \n",
       "1              horizon-europe        www.horizon-europe.gouv.fr  30/10/23  \n",
       "2                         fao                       www.fao.org  30/10/23  \n",
       "3                  copernicus                 gi.copernicus.org  30/10/23  \n",
       "4                      europa                  cordis.europa.eu  30/10/23  \n",
       "..                        ...                               ...       ...  \n",
       "200  databridgemarketresearch  www.databridgemarketresearch.com  30/10/23  \n",
       "201         marketsandmarkets         www.marketsandmarkets.com  30/10/23  \n",
       "202                       wsu          forest.moscowfsl.wsu.edu  30/10/23  \n",
       "203               environment               environment.govt.nz  30/10/23  \n",
       "204      environmentclearance       environmentclearance.nic.in  30/10/23  \n",
       "\n",
       "[205 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>titles</th>\n",
       "      <th>texte</th>\n",
       "      <th>search_term</th>\n",
       "      <th>pages</th>\n",
       "      <th>page_position</th>\n",
       "      <th>type</th>\n",
       "      <th>images</th>\n",
       "      <th>company</th>\n",
       "      <th>domain</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>iphone reconditionné</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>SEO vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td></td>\n",
       "      <td>25/07/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>iphone reconditionné</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>SEO vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td></td>\n",
       "      <td>25/07/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>iphone reconditionné</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>SEO vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td></td>\n",
       "      <td>25/07/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>iphone reconditionné</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>SEO vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td></td>\n",
       "      <td>25/07/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>iphone reconditionné</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>SEO vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td></td>\n",
       "      <td>25/07/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>mac reconditionné</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>SEO vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td></td>\n",
       "      <td>25/07/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>mac reconditionné</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>SEO vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td></td>\n",
       "      <td>25/07/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>mac reconditionné</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>SEO vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td></td>\n",
       "      <td>25/07/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>mac reconditionné</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>SEO vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td></td>\n",
       "      <td>25/07/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>mac reconditionné</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>SEO vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td></td>\n",
       "      <td>25/07/23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      url titles texte           search_term pages page_position      type  \\\n",
       "10   vide   vide  vide  iphone reconditionné  vide          vide  SEO vide   \n",
       "11   vide   vide  vide  iphone reconditionné  vide          vide  SEO vide   \n",
       "27   vide   vide  vide  iphone reconditionné  vide          vide  SEO vide   \n",
       "44   vide   vide  vide  iphone reconditionné  vide          vide  SEO vide   \n",
       "60   vide   vide  vide  iphone reconditionné  vide          vide  SEO vide   \n",
       "..    ...    ...   ...                   ...   ...           ...       ...   \n",
       "717  vide   vide  vide     mac reconditionné  vide          vide  SEO vide   \n",
       "728  vide   vide  vide     mac reconditionné  vide          vide  SEO vide   \n",
       "742  vide   vide  vide     mac reconditionné  vide          vide  SEO vide   \n",
       "752  vide   vide  vide     mac reconditionné  vide          vide  SEO vide   \n",
       "764  vide   vide  vide     mac reconditionné  vide          vide  SEO vide   \n",
       "\n",
       "    images company domain      Date  \n",
       "10    vide    vide         25/07/23  \n",
       "11    vide    vide         25/07/23  \n",
       "27    vide    vide         25/07/23  \n",
       "44    vide    vide         25/07/23  \n",
       "60    vide    vide         25/07/23  \n",
       "..     ...     ...    ...       ...  \n",
       "717   vide    vide         25/07/23  \n",
       "728   vide    vide         25/07/23  \n",
       "742   vide    vide         25/07/23  \n",
       "752   vide    vide         25/07/23  \n",
       "764   vide    vide         25/07/23  \n",
       "\n",
       "[80 rows x 11 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['titles'] == 'vide']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('liste_articles.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
